{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79efbe53-49b2-4bfe-a657-09fb66a2ed6f",
   "metadata": {
    "id": "79efbe53-49b2-4bfe-a657-09fb66a2ed6f"
   },
   "source": [
    "# the VAE model suggested by the paper on the compressed DepMap Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CXhhwqZSbLOd",
   "metadata": {
    "id": "CXhhwqZSbLOd"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a072d-c036-4c65-8699-519e25169a1f",
   "metadata": {
    "id": "d22a072d-c036-4c65-8699-519e25169a1f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "from sklearn.metrics import r2_score\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "from dataset import TS_Compressed_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9P6i0WzvkXvR",
   "metadata": {
    "id": "9P6i0WzvkXvR"
   },
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    EPOCHS = 100,\n",
    "    BATCH_SIZE = 1e3,\n",
    "    LEARNING_RATE = 1e-3,\n",
    "    NUM_LAYERS = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8fed3-c2b4-4d4f-a0af-5840e4641998",
   "metadata": {
    "id": "0fb8fed3-c2b4-4d4f-a0af-5840e4641998"
   },
   "outputs": [],
   "source": [
    "#load the dataframe that contains one to one corresponding of gene id and gene index\n",
    "gene_index = pd.read_csv(\"gene_index.csv\")\n",
    "path = \"TabulaSapiens_CO_compressed.h5ad\"\n",
    "\n",
    "dataset = TS_Compressed_Dataset(gene_index, path)\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "gene_list = gene_index.gene_id.to_list()\n",
    "n_genes = len(gene_list) #the number of total genes\n",
    "n_samples = dataset.dataset[\"sample_idx\"].unique().shape[0] #the number of samples\n",
    "gene_emb_dim = 128 #the gene embedding dimension\n",
    "sample_emb_dim = 64 #the sample embedding dimension\n",
    "\n",
    "\n",
    "##sample embedding initialization parameters\n",
    "sample_emb_init = torch.from_numpy(dataset.compute_sample_init_pca().astype('float32'))\n",
    "n_samples = dataset.dataset[\"sample_idx\"].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4801da-6987-4f0a-8145-d93050dbaa02",
   "metadata": {
    "id": "4a4801da-6987-4f0a-8145-d93050dbaa02"
   },
   "outputs": [],
   "source": [
    "class GeneEmbedding(nn.Module):\n",
    "    def __init__(self, n_genes, gene_emb_dim, gene_list, gene_emb_init = None):\n",
    "        super(GeneEmbedding, self).__init__()\n",
    "\n",
    "        self.n_genes = n_genes\n",
    "        self.gene_emb_dim = gene_emb_dim\n",
    "        self.genes = gene_list\n",
    "\n",
    "        \"\"\"\n",
    "        model the gene embedding as gaussian distributions computed from the mean embeddings and sd embeddings\n",
    "        \"\"\"\n",
    "        if gene_emb_init is not None:\n",
    "            self.emb_mu = nn.Embedding.from_pretrained(gene_emb_init, freeze = False)\n",
    "        else:\n",
    "            # init as [0, 1], as the dirichlet prior is in [0, 1]\n",
    "            self.emb_mu = nn.Embedding.from_pretrained(\n",
    "                torch.rand((n_genes, gene_emb_dim)), freeze = False\n",
    "            )\n",
    "\n",
    "        self.emb_log_sigma = nn.Embedding.from_pretrained(\n",
    "            torch.full((n_genes, gene_emb_dim), np.log(0.5)), freeze = False\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_emb_table(self):\n",
    "        emb_df = pd.DataFrame(self.emb_mu.weight.detach().cpu(),\n",
    "                              index = self.genes,\n",
    "                              columns = [f'FACT_EMB_{i}' for i in range(self.gene_emb_dim)]\n",
    "                              )\n",
    "        emb_df.index.name = 'gene_id'\n",
    "        return emb_df\n",
    "\n",
    "\n",
    "    def get_log_sigma_table(self):\n",
    "        emb_df = pd.DataFrame(self.emb_log_sigma.weight.detach().cpu(),\n",
    "                              index = self.genes,\n",
    "                              columns = [f'FACT_EMB_{i}' for i in range(self.gene_emb_dim)]\n",
    "                              )\n",
    "        emb_df.index.name = 'gene_id'\n",
    "        return emb_df\n",
    "\n",
    "\n",
    "    def get_shape(self):\n",
    "        return (self.n_genes, self.gene_emb_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9de135-d799-4d47-ba84-5f8a247cf505",
   "metadata": {
    "id": "2d9de135-d799-4d47-ba84-5f8a247cf505"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, gene_emb, n_samples, sample_emb_dim, NUM_LAYERS, sample_emb_init = None):\n",
    "        super().__init__()\n",
    "        #initialize the gene embedding\n",
    "        self.gene_emb = gene_emb\n",
    "        #create sample embedding\n",
    "        if sample_emb_init is not None:\n",
    "            self.sample_emb = nn.Embedding.from_pretrained(sample_emb_init, freeze=False)\n",
    "        else:\n",
    "            self.sample_emb = nn.Embedding(n_samples, sample_emb_dim)\n",
    "\n",
    "        joint_emb_dim = sample_emb_dim + self.gene_emb.gene_emb_dim\n",
    "\n",
    "        #the decoder\n",
    "        self.model = nn.Sequential()\n",
    "        for i in range(NUM_LAYERS - 1):\n",
    "            self.model.add_module(f\"layer_{i}\", nn.Linear(joint_emb_dim, joint_emb_dim))\n",
    "            self.model.add_module(f\"relu_{i}\", nn.ReLU())\n",
    "        self.model.add_module(f\"layer_{NUM_LAYERS - 1}\", nn.Linear(joint_emb_dim, 1))\n",
    "\n",
    "\n",
    "    def reparameterization(self, mean, sd):\n",
    "        epsilon = torch.randn_like(sd)    # sampling epsilon\n",
    "        z = mean + sd * epsilon           # reparameterization trick\n",
    "        return z\n",
    "\n",
    "\n",
    "    def get_emb(self, idx):\n",
    "        emb_mu = self.gene_emb.emb_mu.weight\n",
    "        emb_sigma = self.gene_emb.emb_log_sigma.weight.exp()\n",
    "        emb_z = self.reparameterization(emb_mu[idx, :], emb_sigma[idx, :])\n",
    "        return emb_z\n",
    "\n",
    "\n",
    "    def forward(self, gene_index, sample_index):\n",
    "        #get the gene embeddings and sample embeddings from indices\n",
    "        gene_emb_batch = self.get_emb(gene_index)\n",
    "        sample_emb_batch = self.sample_emb(sample_index)\n",
    "        joint_emb = torch.cat((gene_emb_batch, sample_emb_batch), dim = 1)\n",
    "\n",
    "        #use the joint embeddings to predict the score\n",
    "        pred = self.model(joint_emb)\n",
    "        return pred.squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732f229-3e99-4add-ae40-86857b6aa81b",
   "metadata": {
    "id": "9732f229-3e99-4add-ae40-86857b6aa81b"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, loss, BATCH_SIZE, dataset, epoch):\n",
    "    batch_ct = epoch * dataset.get_num_batches_per_epoch(BATCH_SIZE)\n",
    "    cumu_loss = 0\n",
    "    for g_idx, s_idx, target in dataset.get_batches(BATCH_SIZE, 'train'):\n",
    "        model.to(device)\n",
    "        opt.zero_grad()\n",
    "        mu = model(g_idx.to(device, non_blocking=True), s_idx.to(device, non_blocking=True))\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        mse = loss(mu, target)\n",
    "        cumu_loss += mse.item()\n",
    "        mse.backward()\n",
    "        opt.step()\n",
    "\n",
    "        batch_ct += 1\n",
    "        wandb.log({\"batch_loss\": mse.item(), \"batch_ct\": batch_ct})\n",
    "\n",
    "\n",
    "    #torch.mps.empty_cache()\n",
    "    return cumu_loss / dataset.get_num_batches_per_epoch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_r2(model, dataset):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_gene_idx = torch.from_numpy(np.array(dataset.test_table[\"gene_idx\"]))\n",
    "        test_sample_idx = torch.from_numpy(np.array(dataset.test_table[\"sample_idx\"]))\n",
    "        test_target = torch.from_numpy(np.array(dataset.test_table[\"score\"]))\n",
    "        mu = model(test_gene_idx.to(device, non_blocking=True), test_sample_idx.to(device, non_blocking=True))\n",
    "        val_pred = mu.detach().cpu().numpy()\n",
    "        val_target = test_target.detach().cpu().numpy()\n",
    "        model.train()\n",
    "    return r2_score(val_target, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g6VQlsyvmLlB",
   "metadata": {
    "id": "g6VQlsyvmLlB"
   },
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(project=\"vae_ts\", config = config):\n",
    "        #this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "\n",
    "        #initialize the gene embedding\n",
    "        gene_emb = GeneEmbedding(n_genes,\n",
    "                                gene_emb_dim,\n",
    "                                gene_list,\n",
    "                                gene_emb_init = torch.rand(n_genes, gene_emb_dim) - 0.5,\n",
    "                            )\n",
    "        #print(\"Initial Gene Embedding: \", gene_emb.get_emb_table().head(5))\n",
    "\n",
    "        #initialize the model\n",
    "        model= VAE(gene_emb,\n",
    "                   n_samples,\n",
    "                   sample_emb_dim,\n",
    "                   config.NUM_LAYERS,\n",
    "                   sample_emb_init = torch.from_numpy(dataset.compute_sample_init_pca(dim=sample_emb_dim).astype('float32')),\n",
    "                  )\n",
    "\n",
    "        loss = nn.MSELoss(reduction=\"mean\")\n",
    "        opt = torch.optim.Adam(model.parameters(), lr = config.LEARNING_RATE)\n",
    "\n",
    "\n",
    "        wandb.define_metric(\"batch_loss\", step_metric=\"batch_ct\")\n",
    "        wandb.define_metric(\"avg_loss\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"test_r2\", step_metric=\"epoch\")\n",
    "\n",
    "        for epoch in range(config.EPOCHS):\n",
    "            avg_loss = train_epoch(model, opt, loss, config.BATCH_SIZE, dataset, epoch)\n",
    "            wandb.log({\"avg_loss\": avg_loss, \"epoch\": epoch})\n",
    "            r2 = eval_r2(model, dataset)\n",
    "            wandb.log({\"test_r2\": r2, \"epoch\":epoch})\n",
    "            \n",
    "        #save the model in the exchangable ONNX format\n",
    "        test_gene_idx = torch.from_numpy(np.array(dataset.test_table[\"gene_idx\"])).to(device, non_blocking=True)\n",
    "        test_sample_idx = torch.from_numpy(np.array(dataset.test_table[\"sample_idx\"])).to(device, non_blocking=True)\n",
    "        torch.onnx.export(model, (test_gene_idx, test_sample_idx), \"model.onnx\")\n",
    "        wandb.save(\"model.onnx\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B708pjismLnO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b7b3132efca347cd80a382041ff7c1b9",
      "db3e705dbe4d48aa92f949e59913b0d4",
      "6b4755979e174e2a91c654593736b7b3",
      "1136abb5a4b8487fb75cd2c13012e426",
      "a7414374dd604efcb19408757680c7dd",
      "4c18822b98204a47a7e4ef960f5f7131",
      "581371004b1b4943ba3f4f3155c40f77",
      "301ab4ad468a41c8bc67d4893e7ef778"
     ]
    },
    "id": "B708pjismLnO",
    "outputId": "8fca3df6-1317-4fae-fdd5-964f4138b035"
   },
   "outputs": [],
   "source": [
    "model = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MjTdFMAWmL2x",
   "metadata": {
    "id": "MjTdFMAWmL2x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9Gy6gnKCv79G",
   "metadata": {
    "id": "9Gy6gnKCv79G"
   },
   "source": [
    "## The evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547a983-3ec5-4634-8089-d46a05499c8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "a547a983-3ec5-4634-8089-d46a05499c8d",
    "outputId": "fd8b4848-a424-4cd8-c7c7-bc7d070da94f"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        test_gene_idx = torch.from_numpy(np.array(dataset.test_table[\"gene_idx\"]))\n",
    "        test_sample_idx = torch.from_numpy(np.array(dataset.test_table[\"sample_idx\"]))\n",
    "        test_target = torch.from_numpy(np.array(dataset.test_table[\"score\"]))\n",
    "        mu = model(test_gene_idx.to(device, non_blocking=True), test_sample_idx.to(device, non_blocking=True))\n",
    "        val_pred = mu.detach().cpu().numpy()\n",
    "        val_target = test_target.detach().cpu().numpy()\n",
    "result = pd.DataFrame({\n",
    "    \"val_pred\": val_pred,\n",
    "    \"val_target\": val_target})\n",
    "print(\"r2score: \", r2_score(val_target, val_pred))\n",
    "plot = ggplot(result)\n",
    "plot += geom_point(aes(\"val_pred\", \"val_target\"))\n",
    "plot += coord_cartesian(ylim=(0, 1), xlim=(0,1))\n",
    "plot += geom_smooth(aes(\"val_pred\", \"val_target\"))\n",
    "plot += geom_abline(intercept = 0, slope = 1)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dfd1be-3a90-4475-9441-0962b457be35",
   "metadata": {
    "id": "20dfd1be-3a90-4475-9441-0962b457be35"
   },
   "outputs": [],
   "source": [
    "#export the gene embedding\n",
    "\n",
    "export_path = \"TS_Compressed_d128.tsv\"\n",
    "model.gene_emb.get_emb_table().to_csv(export_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62d0cb-89bf-4863-be16-f38f9deb9a9e",
   "metadata": {
    "id": "ee62d0cb-89bf-4863-be16-f38f9deb9a9e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "708a9860-c503-4e2f-8e1a-8db9f7f4c0d4",
   "metadata": {
    "id": "790a74dd-8d72-4eff-8ff8-1873e61c85e4"
   },
   "source": [
    "## exporting embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc90605-46c1-424c-bdb5-a1c774a0ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdfe7f-a18c-46b6-893a-85149ae0cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the UMAP of the gene embedding\n",
    "\"\"\"\n",
    "import umap.plot as umap_plot\n",
    "import umap\n",
    "emb_umap = umap.UMAP().fit(model.gene_emb.get_emb_table())\n",
    "umap.plot.points(emb_umap)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20c19a-1515-4ee7-af78-da0f8f605849",
   "metadata": {
    "id": "ae20c19a-1515-4ee7-af78-da0f8f605849"
   },
   "outputs": [],
   "source": [
    "#the principle components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(2)\n",
    "pcs = pca.fit_transform(model.gene_emb.get_emb_table())\n",
    "df_pcs = pd.DataFrame(data=pcs, columns=['PC1', 'PC2'])\n",
    "plot = ggplot(df_pcs) + geom_point(aes(\"PC1\", \"PC2\"))\n",
    "plot"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1136abb5a4b8487fb75cd2c13012e426": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "301ab4ad468a41c8bc67d4893e7ef778": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c18822b98204a47a7e4ef960f5f7131": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "581371004b1b4943ba3f4f3155c40f77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b4755979e174e2a91c654593736b7b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_581371004b1b4943ba3f4f3155c40f77",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_301ab4ad468a41c8bc67d4893e7ef778",
      "value": 1
     }
    },
    "a7414374dd604efcb19408757680c7dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7b3132efca347cd80a382041ff7c1b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db3e705dbe4d48aa92f949e59913b0d4",
       "IPY_MODEL_6b4755979e174e2a91c654593736b7b3"
      ],
      "layout": "IPY_MODEL_1136abb5a4b8487fb75cd2c13012e426"
     }
    },
    "db3e705dbe4d48aa92f949e59913b0d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7414374dd604efcb19408757680c7dd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4c18822b98204a47a7e4ef960f5f7131",
      "value": "19.718 MB of 19.718 MB uploaded\r"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
