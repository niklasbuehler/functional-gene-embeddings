{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '../../data/input/GTEx/GTEx_mini_random.gct'\n",
    "gtex_df = pd.read_csv(path, skiprows=2, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop zero columns\n",
    "gtex_df = gtex_df.loc[:, (gtex_df != 0).any(axis=0)]\n",
    "gtex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first 2 columns\n",
    "gtex_df.drop(gtex_df.columns[[0, 1]], axis=1, inplace=True)\n",
    "gtex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and transform\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(gtex_df.to_numpy())\n",
    "gtex_df = pd.DataFrame(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(gtex_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTExDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        features = torch.tensor(self.df.iloc[idx], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        return features, features # for Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "input_size = len(gtex_df.columns)\n",
    "encoding_size = 5000\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GTExDataset(train_df)\n",
    "val_dataset = GTExDataset(val_df)\n",
    "test_dataset = GTExDataset(test_df)\n",
    "\n",
    "# Define DataLoader for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_size, encoding_size)\n",
    "        self.decoder = nn.Linear(encoding_size, input_size)\n",
    "        self.nonlin = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.nonlin(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.nonlin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = Autoencoder(input_size, encoding_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loss_values = []\n",
    "val_loss_values = []\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    train_epoch_losses= []\n",
    "    val_epoch_losses=[]\n",
    "    # Train step\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_epoch_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss_values.append(np.mean(train_epoch_losses))\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {np.mean(train_epoch_losses):.4f}')\n",
    "\n",
    "    # Val step\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in train_loader:\n",
    "            model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_epoch_losses.append(loss.item())\n",
    "        val_loss_values.append(np.mean(val_epoch_losses))\n",
    "        print(f'Validation Loss: {np.mean(val_epoch_losses):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.plot(np.array(train_loss_values), 'r')\n",
    "    plt.plot(np.array(val_loss_values), 'b')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cbd9af743c416a448b7bd76b7d3b5d57d0478ef5d583f623702bb679bd48493"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('sysgen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
