{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from src.Autoencoder import Autoencoder as AE\n",
    "from src.early_stopping import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '../../data/input/GTEx/GTEx_mini_random.gct'\n",
    "gtex_df = pd.read_csv(path, skiprows=2, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop zero columns\n",
    "gtex_df = gtex_df.loc[:, (gtex_df != 0).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(gtex_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hparams\n",
    "hparams = {\n",
    "    \"input_size\": len(gtex_df.columns) - 2,\n",
    "    \"emb_dim\": 128,    \n",
    "}\n",
    "config = {\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-5\n",
    "}\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTExDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.gene_ids = self.df['Name']\n",
    "        # drop first 2 columns\n",
    "        self.df.drop(self.df.columns[[0, 1]], axis=1, inplace=True)\n",
    "        scaler = MinMaxScaler()\n",
    "        df_scaled = scaler.fit_transform(self.df.to_numpy())\n",
    "        self.df = pd.DataFrame(df_scaled)\n",
    "\n",
    "    def get_gene_ids(self):\n",
    "        return self.gene_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        features = torch.tensor(self.df.iloc[idx], dtype=torch.float32)\n",
    "\n",
    "        return features, features # for Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GTExDataset(train_df)\n",
    "val_dataset = GTExDataset(val_df)\n",
    "test_dataset = GTExDataset(test_df)\n",
    "full_dataset = GTExDataset(gtex_df)\n",
    "# Define DataLoader for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "full_loader = DataLoader(full_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = AE(hparams[\"input_size\"], hparams[\"emb_dim\"])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "train_loss_values = []\n",
    "val_loss_values = []\n",
    "\n",
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable),total=len(iterable), ncols=150, desc=desc)\n",
    "epochs = config['epochs']\n",
    "es = EarlyStopping(patience=5)\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Train step\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]')\n",
    "\n",
    "    for train_iteration, batch in training_loop:\n",
    "        optimizer.zero_grad() # Reset the gradients - VERY important! Otherwise they accumulate.\n",
    "        inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        # Update the progress bar.\n",
    "        training_loop.set_postfix(curr_train_loss = \"{:.8f}\".format(training_loss / (train_iteration + 1)))\n",
    "    training_loss /= len(train_loader)\n",
    "    train_loss_values.append(training_loss)\n",
    "    # Val step\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]')\n",
    "    with torch.no_grad():\n",
    "        for val_iteration, batch in val_loop:\n",
    "            inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            validation_loss += loss.item()\n",
    "            # Update the progress bar.\n",
    "            val_loop.set_postfix(val_loss = \"{:.8f}\".format(validation_loss / (val_iteration + 1)))\n",
    "    validation_loss /= len(val_loader)\n",
    "    val_loss_values.append(validation_loss)\n",
    "    if es.early_stop(validation_loss): \n",
    "        print(f\"Early stopping at this epoch: {epoch}\")\n",
    "        break\n",
    "print(\"Finished training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.plot(np.array(train_loss_values), 'r', label='train loss')\n",
    "    plt.plot(np.array(val_loss_values), 'b', label='val loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "# Extract embeddings\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, _ in full_loader:\n",
    "        x = model.encoder(inputs)\n",
    "        embeddings.append(x)\n",
    "embeddings = torch.vstack(embeddings)\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emb_df = pd.DataFrame(\n",
    "    data = embeddings,\n",
    "    index = full_dataset.get_gene_ids(),\n",
    "    columns = [f'EMB_{i}' for i in range(hparams[\"emb_dim\"])]\n",
    ")\n",
    "emb_df.index.name = \"gene_id\"\n",
    "emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df.index = emb_df.index.str.split('.').str[0]\n",
    "emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df.to_csv(f\"../../data/embeddings/GTEx_AE_128.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cbd9af743c416a448b7bd76b7d3b5d57d0478ef5d583f623702bb679bd48493"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('sysgen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
