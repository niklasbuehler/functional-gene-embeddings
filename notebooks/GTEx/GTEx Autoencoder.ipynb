{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "432062704d49cf6f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# GTEx Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4cc8ac1910a84",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm.auto import tqdm\n",
    "from cmapPy.pandasGEXpress.parse_gct import parse\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da932e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full dataset is not tracked in the repo. You need to download it\n",
    "full_data_path = '../../data/input/GTEx/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct'\n",
    "full_data_path = '../../data/input/GTEx/GTEx_mini.gct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate data split and metadata\n",
    "file = open(full_data_path)\n",
    "file.readline()\n",
    "metadata = file.readline()\n",
    "metadata = metadata.split('\\t')\n",
    "data_nr_rows = int(metadata[0])\n",
    "data_nr_cols = int(metadata[1])\n",
    "train_chunks_size = int(data_nr_rows * 0.6)\n",
    "val_chunks_size = int(data_nr_rows * 0.2)\n",
    "test_chunks_size = int(data_nr_rows * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f385f5d48e85199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T16:58:30.732853450Z",
     "start_time": "2024-01-15T16:58:30.720067996Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    # drop name and describtion\n",
    "    batch.drop(batch.columns[[0, 1]], axis=1, inplace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = scaler.fit_transform(batch.to_numpy())\n",
    "    df = pd.DataFrame(df_scaled)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14998d25-7dae-4fee-b0e8-e0a32f61c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTExDataset(Dataset):\n",
    "    def __init__(self, nr_rows, type, transform=None):\n",
    "        self.type = type\n",
    "        self.chunks_reader = None\n",
    "        self.nr_rows = nr_rows\n",
    "        self.transform = transform\n",
    "        self.current_chunk_nr = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nr_rows\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx == 0:\n",
    "            self.refresh_reader()\n",
    "            chunk = self.chunks_reader.get_chunk()\n",
    "            self.current_chunk = process_batch(chunk)\n",
    "            self.current_chunk_nr = 0\n",
    "        if (int(idx / self.chunks_reader.chunksize)) > self.current_chunk_nr:\n",
    "            self.current_chunk_nr += 1\n",
    "            chunk = self.chunks_reader.get_chunk()\n",
    "            self.current_chunk = process_batch(chunk)\n",
    "        index = idx % self.chunks_reader.chunksize\n",
    "        features = torch.tensor(self.current_chunk.iloc[index], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        return features, features # for Autoencoder\n",
    "    \n",
    "    def refresh_reader(self):\n",
    "        if self.type == 'train':\n",
    "            self.chunks_reader = pd.read_csv(full_data_path, skiprows=2, sep=\"\\t\", chunksize=256, nrows= int(data_nr_rows * 0.6))\n",
    "        elif self.type == 'val':\n",
    "            self.chunks_reader = pd.read_csv(full_data_path, skiprows=2 + int(data_nr_rows * 0.6), sep=\"\\t\", chunksize=256, nrows= int(data_nr_rows * 0.2))\n",
    "        else:\n",
    "            self.chunks_reader = pd.read_csv(full_data_path, skiprows=2 + int(data_nr_rows * 0.8), sep=\"\\t\", chunksize=256, nrows= int(data_nr_rows * 0.2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ce141-3ce5-4155-95a4-44c167d4faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "input_size = data_nr_cols\n",
    "encoding_size = 5000\n",
    "learning_rate = 1e-4\n",
    "epochs = 50\n",
    "batch_size = 265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc167e-29a9-4b5c-9bd0-aa6a67cf9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GTExDataset(nr_rows=train_chunks_size, type='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = GTExDataset(nr_rows=val_chunks_size, type='val')\n",
    "val_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = GTExDataset(nr_rows=test_chunks_size, type='test')\n",
    "test_loader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69df8f543fdaa0b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_size, encoding_size)\n",
    "        self.decoder = nn.Linear(encoding_size, input_size)\n",
    "        self.nonlin = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.nonlin(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.nonlin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e945eff-355c-4c14-9927-cf56e0730964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = Autoencoder(input_size, encoding_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Val step\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        print(f'Validation Loss: {loss.item():.4f}')\n",
    "\n",
    "# Extract embeddings\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, _ in train_loader:\n",
    "        embeddings = model.encoder(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6af2b4-ad8b-468c-8318-5c6d42ccbacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cbd9af743c416a448b7bd76b7d3b5d57d0478ef5d583f623702bb679bd48493"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('sysgen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
